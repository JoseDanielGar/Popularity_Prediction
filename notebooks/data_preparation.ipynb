{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a55b2fd2",
   "metadata": {},
   "source": [
    "# Preparación de Datos para Modelado\n",
    "\n",
    "Este notebook realiza la preparación final de los datos para el entrenamiento de modelos de machine learning:\n",
    "\n",
    "- Cargar librerías necesarias\n",
    "- Identificar y codificar variables categóricas\n",
    "- Dividir el conjunto de datos en entrenamiento y prueba\n",
    "- Guardar los conjuntos de datos procesados\n",
    "\n",
    "**Nota:** Se asume que los datos ya han sido limpiados previamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b25829",
   "metadata": {},
   "source": [
    "## 1. Cargar Librerías Requeridas\n",
    "\n",
    "Importar todas las librerías necesarias para la preparación de datos y codificación de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d53f9382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Librerías importadas exitosamente!\n",
      "Pandas versión: 2.3.2\n",
      "NumPy versión: 2.3.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Suprimir warnings para una salida más limpia\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de pandas para mejor visualización\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"✓ Librerías importadas exitosamente!\")\n",
    "print(f\"Pandas versión: {pd.__version__}\")\n",
    "print(f\"NumPy versión: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0e0a58",
   "metadata": {},
   "source": [
    "## 2. Cargar Configuración y Datos\n",
    "\n",
    "Cargar los parámetros desde el archivo `params.yaml` y el conjunto de datos limpio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46be087a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración cargada:\n",
      "========================================\n",
      "input_path: data/prep/dataset_cleaned.csv\n",
      "output_path_train: data/train\n",
      "output_path_test: data/test\n",
      "split: 0.2\n",
      "seed: 20250901\n",
      "\n",
      "✓ Configuración cargada exitosamente!\n",
      "✓ División de test: 20.0%\n",
      "✓ Semilla aleatoria: 20250901\n"
     ]
    }
   ],
   "source": [
    "# Cargar configuración desde params.yaml\n",
    "config = yaml.safe_load(open(\"../params.yaml\"))[\"prepare\"]\n",
    "\n",
    "print(\"Configuración cargada:\")\n",
    "print(\"=\" * 40)\n",
    "for key, value in config.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Extraer parámetros\n",
    "input_path = \"../\" + config[\"input_path\"]\n",
    "output_path_train = \"../\" + config[\"output_path_train\"]\n",
    "output_path_test = \"../\" + config[\"output_path_test\"]\n",
    "test_split = config[\"split\"]\n",
    "random_seed = config[\"seed\"]\n",
    "\n",
    "print(f\"\\n✓ Configuración cargada exitosamente!\")\n",
    "print(f\"✓ División de test: {test_split*100}%\")\n",
    "print(f\"✓ Semilla aleatoria: {random_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5c776ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos desde: ../data/prep/dataset_cleaned.csv\n",
      "✓ Datos cargados exitosamente!\n",
      "✓ Forma del conjunto de datos: (113999, 16)\n",
      "✓ Total de registros: 113,999\n",
      "✓ Total de características: 16\n",
      "\n",
      "✓ Semilla aleatoria establecida: 20250901\n"
     ]
    }
   ],
   "source": [
    "# Cargar el conjunto de datos limpio\n",
    "print(f\"Cargando datos desde: {input_path}\")\n",
    "\n",
    "if os.path.exists(input_path):\n",
    "    df = pd.read_csv(input_path)\n",
    "    print(f\"✓ Datos cargados exitosamente!\")\n",
    "    print(f\"✓ Forma del conjunto de datos: {df.shape}\")\n",
    "    print(f\"✓ Total de registros: {len(df):,}\")\n",
    "    print(f\"✓ Total de características: {df.shape[1]}\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Archivo no encontrado: {input_path}\")\n",
    "\n",
    "# Establecer semilla para reproducibilidad\n",
    "np.random.seed(random_seed)\n",
    "print(f\"\\n✓ Semilla aleatoria establecida: {random_seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75be44f4",
   "metadata": {},
   "source": [
    "## 3. Exploración de Variables\n",
    "\n",
    "Analizar el conjunto de datos para identificar tipos de variables y su distribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3697844f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFORMACIÓN GENERAL DEL CONJUNTO DE DATOS\n",
      "==================================================\n",
      "Forma: (113999, 16)\n",
      "\n",
      "Primeras 5 filas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>False</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.715</td>\n",
       "      <td>87.917</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>149610</td>\n",
       "      <td>False</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>1</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.267</td>\n",
       "      <td>77.489</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>210826</td>\n",
       "      <td>False</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.120</td>\n",
       "      <td>76.332</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>201933</td>\n",
       "      <td>False</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.143</td>\n",
       "      <td>181.740</td>\n",
       "      <td>3</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>198853</td>\n",
       "      <td>False</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.167</td>\n",
       "      <td>119.949</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  duration_ms  explicit  danceability  energy  key  loudness  \\\n",
       "0          73       230666     False         0.676  0.4610    1    -6.746   \n",
       "1          55       149610     False         0.420  0.1660    1   -17.235   \n",
       "2          57       210826     False         0.438  0.3590    0    -9.734   \n",
       "3          71       201933     False         0.266  0.0596    0   -18.515   \n",
       "4          82       198853     False         0.618  0.4430    2    -9.681   \n",
       "\n",
       "   mode  speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "0     0       0.1430        0.0322          0.000001    0.3580    0.715   \n",
       "1     1       0.0763        0.9240          0.000006    0.1010    0.267   \n",
       "2     1       0.0557        0.2100          0.000000    0.1170    0.120   \n",
       "3     1       0.0363        0.9050          0.000071    0.1320    0.143   \n",
       "4     1       0.0526        0.4690          0.000000    0.0829    0.167   \n",
       "\n",
       "     tempo  time_signature track_genre  \n",
       "0   87.917               4    acoustic  \n",
       "1   77.489               4    acoustic  \n",
       "2   76.332               4    acoustic  \n",
       "3  181.740               3    acoustic  \n",
       "4  119.949               4    acoustic  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Información de tipos de datos:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 113999 entries, 0 to 113998\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   popularity        113999 non-null  int64  \n",
      " 1   duration_ms       113999 non-null  int64  \n",
      " 2   explicit          113999 non-null  bool   \n",
      " 3   danceability      113999 non-null  float64\n",
      " 4   energy            113999 non-null  float64\n",
      " 5   key               113999 non-null  int64  \n",
      " 6   loudness          113999 non-null  float64\n",
      " 7   mode              113999 non-null  int64  \n",
      " 8   speechiness       113999 non-null  float64\n",
      " 9   acousticness      113999 non-null  float64\n",
      " 10  instrumentalness  113999 non-null  float64\n",
      " 11  liveness          113999 non-null  float64\n",
      " 12  valence           113999 non-null  float64\n",
      " 13  tempo             113999 non-null  float64\n",
      " 14  time_signature    113999 non-null  int64  \n",
      " 15  track_genre       113999 non-null  object \n",
      "dtypes: bool(1), float64(9), int64(5), object(1)\n",
      "memory usage: 13.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Mostrar información general del conjunto de datos\n",
    "print(\"INFORMACIÓN GENERAL DEL CONJUNTO DE DATOS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Forma: {df.shape}\")\n",
    "print(f\"\\nPrimeras 5 filas:\")\n",
    "display(df.head())\n",
    "\n",
    "print(f\"\\nInformación de tipos de datos:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f381d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>113999.000000</td>\n",
       "      <td>1.139990e+05</td>\n",
       "      <td>113999</td>\n",
       "      <td>113999.000000</td>\n",
       "      <td>113999.000000</td>\n",
       "      <td>113999.000000</td>\n",
       "      <td>113999.000000</td>\n",
       "      <td>113999.000000</td>\n",
       "      <td>113999.000000</td>\n",
       "      <td>113999.000000</td>\n",
       "      <td>113999.000000</td>\n",
       "      <td>113999.000000</td>\n",
       "      <td>113999.000000</td>\n",
       "      <td>113999.000000</td>\n",
       "      <td>113999.000000</td>\n",
       "      <td>113999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.238827</td>\n",
       "      <td>2.280312e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.566801</td>\n",
       "      <td>0.641383</td>\n",
       "      <td>5.309126</td>\n",
       "      <td>-8.258950</td>\n",
       "      <td>0.637558</td>\n",
       "      <td>0.084652</td>\n",
       "      <td>0.314907</td>\n",
       "      <td>0.156051</td>\n",
       "      <td>0.213554</td>\n",
       "      <td>0.474066</td>\n",
       "      <td>122.147695</td>\n",
       "      <td>3.904034</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.304959</td>\n",
       "      <td>1.072961e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.173543</td>\n",
       "      <td>0.251530</td>\n",
       "      <td>3.559999</td>\n",
       "      <td>5.029357</td>\n",
       "      <td>0.480708</td>\n",
       "      <td>0.105733</td>\n",
       "      <td>0.332522</td>\n",
       "      <td>0.309556</td>\n",
       "      <td>0.190378</td>\n",
       "      <td>0.259261</td>\n",
       "      <td>29.978290</td>\n",
       "      <td>0.432623</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.586000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-49.531000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.740660e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.456000</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-10.013000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>99.218500</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>2.129060e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-7.004000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.464000</td>\n",
       "      <td>122.017000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>2.615060e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.854000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-5.003000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.084500</td>\n",
       "      <td>0.597500</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.273000</td>\n",
       "      <td>0.683000</td>\n",
       "      <td>140.071000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.237295e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.532000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>243.372000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           popularity   duration_ms explicit   danceability         energy  \\\n",
       "count   113999.000000  1.139990e+05   113999  113999.000000  113999.000000   \n",
       "unique            NaN           NaN        2            NaN            NaN   \n",
       "top               NaN           NaN    False            NaN            NaN   \n",
       "freq              NaN           NaN   104252            NaN            NaN   \n",
       "mean        33.238827  2.280312e+05      NaN       0.566801       0.641383   \n",
       "std         22.304959  1.072961e+05      NaN       0.173543       0.251530   \n",
       "min          0.000000  8.586000e+03      NaN       0.000000       0.000000   \n",
       "25%         17.000000  1.740660e+05      NaN       0.456000       0.472000   \n",
       "50%         35.000000  2.129060e+05      NaN       0.580000       0.685000   \n",
       "75%         50.000000  2.615060e+05      NaN       0.695000       0.854000   \n",
       "max        100.000000  5.237295e+06      NaN       0.985000       1.000000   \n",
       "\n",
       "                  key       loudness           mode    speechiness  \\\n",
       "count   113999.000000  113999.000000  113999.000000  113999.000000   \n",
       "unique            NaN            NaN            NaN            NaN   \n",
       "top               NaN            NaN            NaN            NaN   \n",
       "freq              NaN            NaN            NaN            NaN   \n",
       "mean         5.309126      -8.258950       0.637558       0.084652   \n",
       "std          3.559999       5.029357       0.480708       0.105733   \n",
       "min          0.000000     -49.531000       0.000000       0.000000   \n",
       "25%          2.000000     -10.013000       0.000000       0.035900   \n",
       "50%          5.000000      -7.004000       1.000000       0.048900   \n",
       "75%          8.000000      -5.003000       1.000000       0.084500   \n",
       "max         11.000000       4.532000       1.000000       0.965000   \n",
       "\n",
       "         acousticness  instrumentalness       liveness        valence  \\\n",
       "count   113999.000000     113999.000000  113999.000000  113999.000000   \n",
       "unique            NaN               NaN            NaN            NaN   \n",
       "top               NaN               NaN            NaN            NaN   \n",
       "freq              NaN               NaN            NaN            NaN   \n",
       "mean         0.314907          0.156051       0.213554       0.474066   \n",
       "std          0.332522          0.309556       0.190378       0.259261   \n",
       "min          0.000000          0.000000       0.000000       0.000000   \n",
       "25%          0.016900          0.000000       0.098000       0.260000   \n",
       "50%          0.169000          0.000042       0.132000       0.464000   \n",
       "75%          0.597500          0.049000       0.273000       0.683000   \n",
       "max          0.996000          1.000000       1.000000       0.995000   \n",
       "\n",
       "                tempo  time_signature track_genre  \n",
       "count   113999.000000   113999.000000      113999  \n",
       "unique            NaN             NaN         114  \n",
       "top               NaN             NaN    acoustic  \n",
       "freq              NaN             NaN        1000  \n",
       "mean       122.147695        3.904034         NaN  \n",
       "std         29.978290        0.432623         NaN  \n",
       "min          0.000000        0.000000         NaN  \n",
       "25%         99.218500        4.000000         NaN  \n",
       "50%        122.017000        4.000000         NaN  \n",
       "75%        140.071000        4.000000         NaN  \n",
       "max        243.372000        5.000000         NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dcbc503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANÁLISIS DE TIPOS DE VARIABLES\n",
      "==================================================\n",
      "\n",
      "Variables categóricas (4):\n",
      "  - track_genre: object (valores únicos: 114)\n",
      "  - key: int64 (valores únicos: 12)\n",
      "  - mode: int64 (valores únicos: 2)\n",
      "  - time_signature: int64 (valores únicos: 5)\n",
      "Variables numéricas (11):\n",
      "  - popularity: int64\n",
      "  - duration_ms: int64\n",
      "  - danceability: float64\n",
      "  - energy: float64\n",
      "  - loudness: float64\n",
      "  - speechiness: float64\n",
      "  - acousticness: float64\n",
      "  - instrumentalness: float64\n",
      "  - liveness: float64\n",
      "  - valence: float64\n",
      "  - tempo: float64\n",
      "\n",
      "Variables booleanas (1):\n",
      "  - explicit: bool\n"
     ]
    }
   ],
   "source": [
    "# Identificar tipos de variables\n",
    "print(\"ANÁLISIS DE TIPOS DE VARIABLES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Variables categóricas (object y category)\n",
    "categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "categorical_columns += ['key', 'mode', 'time_signature']\n",
    "print(f\"\\nVariables categóricas ({len(categorical_columns)}):\")\n",
    "for col in categorical_columns:\n",
    "    unique_values = df[col].nunique()\n",
    "    print(f\"  - {col}: {df[col].dtype} (valores únicos: {unique_values})\")\n",
    "\n",
    "# Variables numéricas\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# Excluir columnas numéricas que están en categorical_columns\n",
    "numeric_columns = [col for col in numeric_columns if col not in categorical_columns]\n",
    "print(f\"Variables numéricas ({len(numeric_columns)}):\")\n",
    "for col in numeric_columns:\n",
    "    print(f\"  - {col}: {df[col].dtype}\")\n",
    "\n",
    "# Variables booleanas\n",
    "boolean_columns = df.select_dtypes(include=['bool']).columns.tolist()\n",
    "print(f\"\\nVariables booleanas ({len(boolean_columns)}):\")\n",
    "for col in boolean_columns:\n",
    "    print(f\"  - {col}: {df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d34914c",
   "metadata": {},
   "source": [
    "## 4. Normalización de Variables Numéricas\n",
    "\n",
    "Analizar y normalizar las variables numéricas para mejorar el rendimiento de los algoritmos de machine learning que son sensibles a la escala de las características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "199de02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANÁLISIS ESTADÍSTICO DE VARIABLES NUMÉRICAS A NORMALIZAR\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>loudness</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.139990e+05</td>\n",
       "      <td>113999.000000</td>\n",
       "      <td>113999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.280312e+05</td>\n",
       "      <td>-8.258950</td>\n",
       "      <td>122.147695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.072961e+05</td>\n",
       "      <td>5.029357</td>\n",
       "      <td>29.978290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.586000e+03</td>\n",
       "      <td>-49.531000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.740660e+05</td>\n",
       "      <td>-10.013000</td>\n",
       "      <td>99.218500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.129060e+05</td>\n",
       "      <td>-7.004000</td>\n",
       "      <td>122.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.615060e+05</td>\n",
       "      <td>-5.003000</td>\n",
       "      <td>140.071000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.237295e+06</td>\n",
       "      <td>4.532000</td>\n",
       "      <td>243.372000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        duration_ms       loudness          tempo\n",
       "count  1.139990e+05  113999.000000  113999.000000\n",
       "mean   2.280312e+05      -8.258950     122.147695\n",
       "std    1.072961e+05       5.029357      29.978290\n",
       "min    8.586000e+03     -49.531000       0.000000\n",
       "25%    1.740660e+05     -10.013000      99.218500\n",
       "50%    2.129060e+05      -7.004000     122.017000\n",
       "75%    2.615060e+05      -5.003000     140.071000\n",
       "max    5.237295e+06       4.532000     243.372000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rangos de valores para cada variable numérica a normalizar:\n",
      "--------------------------------------------------\n",
      "duration_ms:\n",
      "  • Rango: [8586.000, 5237295.000]\n",
      "  • Media: 228031.153, Desv. Estándar: 107296.058\n",
      "  • Ratio (max/min): 609.98\n",
      "\n",
      "loudness:\n",
      "  • Rango: [-49.531, 4.532]\n",
      "  • Media: -8.259, Desv. Estándar: 5.029\n",
      "  • Ratio (max/min): -0.09\n",
      "\n",
      "tempo:\n",
      "  • Rango: [0.000, 243.372]\n",
      "  • Media: 122.148, Desv. Estándar: 29.978\n",
      "  • Ratio (max/min): Inf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Análisis estadístico de variables numéricas\n",
    "columns_to_normalize = ['duration_ms','loudness', 'tempo']\n",
    "\n",
    "print(\"ANÁLISIS ESTADÍSTICO DE VARIABLES NUMÉRICAS A NORMALIZAR\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Estadísticas descriptivas de variables numéricas\n",
    "numeric_stats = df[columns_to_normalize].describe()\n",
    "display(numeric_stats)\n",
    "\n",
    "print(f\"\\nRangos de valores para cada variable numérica a normalizar:\")\n",
    "print(\"-\" * 50)\n",
    "for col in columns_to_normalize:\n",
    "    min_val = df[col].min()\n",
    "    max_val = df[col].max()\n",
    "    mean_val = df[col].mean()\n",
    "    std_val = df[col].std()\n",
    "    print(f\"{col}:\")\n",
    "    print(f\"  • Rango: [{min_val:.3f}, {max_val:.3f}]\")\n",
    "    print(f\"  • Media: {mean_val:.3f}, Desv. Estándar: {std_val:.3f}\")\n",
    "    ratio = max_val / min_val if min_val != 0 else 'Inf'\n",
    "    if isinstance(ratio, str):\n",
    "        print(f\"  • Ratio (max/min): {ratio}\")\n",
    "    else:\n",
    "        print(f\"  • Ratio (max/min): {ratio:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "738a74e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETERMINACIÓN DE ESTRATEGIA DE NORMALIZACIÓN\n",
      "==================================================\n",
      "✓ duration_ms: StandardScaler\n",
      "  • Outliers: 4.9%\n",
      "  • Ratio rango: 609.98\n",
      "\n",
      "✓ loudness: RobustScaler\n",
      "  • Outliers: 5.4%\n",
      "  • Ratio rango: inf\n",
      "\n",
      "✓ tempo: StandardScaler\n",
      "  • Outliers: 0.5%\n",
      "  • Ratio rango: inf\n",
      "\n",
      "Total de variables a normalizar: 3\n"
     ]
    }
   ],
   "source": [
    "# Determinación de estrategia de normalización\n",
    "if columns_to_normalize:\n",
    "    print(\"DETERMINACIÓN DE ESTRATEGIA DE NORMALIZACIÓN\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Análisis de distribuciones para determinar el mejor método\n",
    "    variables_to_normalize = []\n",
    "    normalization_strategy = {}\n",
    "    \n",
    "    for col in columns_to_normalize:\n",
    "        # Calcular estadísticas para determinar el método apropiado\n",
    "        q1 = df[col].quantile(0.25)\n",
    "        q3 = df[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        \n",
    "        # Detectar outliers usando IQR\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]\n",
    "        outlier_percentage = len(outliers) / len(df) * 100\n",
    "        \n",
    "        # Determinar el rango de valores\n",
    "        min_val = df[col].min()\n",
    "        max_val = df[col].max()\n",
    "        range_ratio = max_val / min_val if min_val > 0 else float('inf')\n",
    "        \n",
    "        # Decidir método de normalización\n",
    "        if outlier_percentage > 5:  # Si hay muchos outliers, usar RobustScaler\n",
    "            method = \"RobustScaler\"\n",
    "            scaler = RobustScaler()\n",
    "        elif range_ratio > 100:  # Si el rango es muy amplio, usar StandardScaler\n",
    "            method = \"StandardScaler\"\n",
    "            scaler = StandardScaler()\n",
    "        else:  # Para rangos moderados, usar MinMaxScaler\n",
    "            method = \"MinMaxScaler\"\n",
    "            scaler = MinMaxScaler()\n",
    "        \n",
    "        variables_to_normalize.append(col)\n",
    "        normalization_strategy[col] = {'method': method, 'scaler': scaler, 'outlier_pct': outlier_percentage}\n",
    "        \n",
    "        print(f\"✓ {col}: {method}\")\n",
    "        print(f\"  • Outliers: {outlier_percentage:.1f}%\")\n",
    "        print(f\"  • Ratio rango: {range_ratio:.2f}\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"Total de variables a normalizar: {len(variables_to_normalize)}\")\n",
    "else:\n",
    "    variables_to_normalize = []\n",
    "    normalization_strategy = {}\n",
    "    print(\"✓ No hay variables numéricas para normalizar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04465dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APLICANDO NORMALIZACIÓN\n",
      "==================================================\n",
      "✓ duration_ms (StandardScaler):\n",
      "  • Antes: μ=228031.153, σ=107296.058\n",
      "  • Después: μ=-0.000, σ=1.000\n",
      "  • Rango después: [-2.045, 46.687]\n",
      "\n",
      "✓ loudness (RobustScaler):\n",
      "  • Antes: μ=-8.259, σ=5.029\n",
      "  • Después: μ=-0.250, σ=1.004\n",
      "  • Rango después: [-8.488, 2.303]\n",
      "\n",
      "✓ tempo (StandardScaler):\n",
      "  • Antes: μ=122.148, σ=29.978\n",
      "  • Después: μ=0.000, σ=1.000\n",
      "  • Rango después: [-4.075, 4.044]\n",
      "\n",
      "✓ Normalización completada!\n",
      "✓ Variables normalizadas: 3\n",
      "✓ Scalers guardados: 3\n"
     ]
    }
   ],
   "source": [
    "# Aplicar normalización a las variables numéricas\n",
    "df_normalized = df.copy()\n",
    "scalers = {}  # Diccionario para guardar los scalers\n",
    "\n",
    "if variables_to_normalize:\n",
    "    print(\"APLICANDO NORMALIZACIÓN\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for col in variables_to_normalize:\n",
    "        method = normalization_strategy[col]['method']\n",
    "        scaler = normalization_strategy[col]['scaler']\n",
    "        \n",
    "        # Aplicar normalización\n",
    "        original_values = df[col].values.reshape(-1, 1)\n",
    "        normalized_values = scaler.fit_transform(original_values)\n",
    "        df_normalized[col] = normalized_values.flatten()\n",
    "        \n",
    "        # Guardar el scaler para uso futuro\n",
    "        scalers[f'{col}_scaler'] = scaler\n",
    "        \n",
    "        # Mostrar estadísticas antes y después\n",
    "        original_mean = df[col].mean()\n",
    "        original_std = df[col].std()\n",
    "        normalized_mean = df_normalized[col].mean()\n",
    "        normalized_std = df_normalized[col].std()\n",
    "        \n",
    "        print(f\"✓ {col} ({method}):\")\n",
    "        print(f\"  • Antes: μ={original_mean:.3f}, σ={original_std:.3f}\")\n",
    "        print(f\"  • Después: μ={normalized_mean:.3f}, σ={normalized_std:.3f}\")\n",
    "        print(f\"  • Rango después: [{df_normalized[col].min():.3f}, {df_normalized[col].max():.3f}]\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"✓ Normalización completada!\")\n",
    "    print(f\"✓ Variables normalizadas: {len(variables_to_normalize)}\")\n",
    "    print(f\"✓ Scalers guardados: {len(scalers)}\")\n",
    "else:\n",
    "    print(\"✓ No hay variables para normalizar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc277c23",
   "metadata": {},
   "source": [
    "## 5. Identificar y Codificar Variables Categóricas\n",
    "\n",
    "Procesar las variables categóricas utilizando técnicas de codificación apropiadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f72758b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANÁLISIS DETALLADO DE VARIABLES CATEGÓRICAS\n",
      "==================================================\n",
      "\n",
      "Variable: track_genre\n",
      "Valores únicos: 114\n",
      "Top 10 valores más frecuentes:\n",
      "track_genre\n",
      "acoustic             1000\n",
      "afrobeat             1000\n",
      "psych-rock           1000\n",
      "progressive-house    1000\n",
      "power-pop            1000\n",
      "pop                  1000\n",
      "pop-film             1000\n",
      "piano                1000\n",
      "party                1000\n",
      "pagode               1000\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "\n",
      "Variable: key\n",
      "Valores únicos: 12\n",
      "Top 10 valores más frecuentes:\n",
      "key\n",
      "7     13244\n",
      "0     13061\n",
      "2     11644\n",
      "9     11313\n",
      "1     10772\n",
      "5      9368\n",
      "11     9282\n",
      "4      9008\n",
      "6      7921\n",
      "10     7456\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "\n",
      "Variable: mode\n",
      "Valores únicos: 2\n",
      "Top 10 valores más frecuentes:\n",
      "mode\n",
      "1    72681\n",
      "0    41318\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "\n",
      "Variable: time_signature\n",
      "Valores únicos: 5\n",
      "Top 10 valores más frecuentes:\n",
      "time_signature\n",
      "4    101842\n",
      "3      9195\n",
      "5      1826\n",
      "1       973\n",
      "0       163\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Análisis detallado de variables categóricas\n",
    "if categorical_columns:\n",
    "    print(\"ANÁLISIS DETALLADO DE VARIABLES CATEGÓRICAS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        unique_count = df[col].nunique()\n",
    "        sample_values = df[col].value_counts().head(10)\n",
    "        \n",
    "        print(f\"\\nVariable: {col}\")\n",
    "        print(f\"Valores únicos: {unique_count}\")\n",
    "        print(f\"Top 10 valores más frecuentes:\")\n",
    "        print(sample_values)\n",
    "        print(\"-\" * 30)\n",
    "else:\n",
    "    print(\"✓ No se encontraron variables categóricas para procesar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09df4ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESTRATEGIA DE CODIFICACIÓN\n",
      "==================================================\n",
      "✓ track_genre: Label Encoding (cardinalidad: 114)\n",
      "✓ key: Label Encoding (cardinalidad: 12)\n",
      "✓ mode: One-Hot Encoding (cardinalidad: 2)\n",
      "✓ time_signature: One-Hot Encoding (cardinalidad: 5)\n",
      "\n",
      "Resumen:\n",
      "Variables para One-Hot Encoding: 2\n",
      "Variables para Label Encoding: 2\n"
     ]
    }
   ],
   "source": [
    "# Determinar estrategia de codificación para cada variable categórica\n",
    "if categorical_columns:\n",
    "    print(\"ESTRATEGIA DE CODIFICACIÓN\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Separar variables por cardinalidad\n",
    "    low_cardinality = []  # Para One-Hot Encoding (<=10 categorías)\n",
    "    high_cardinality = [] # Para Label Encoding (>10 categorías)\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        unique_count = df[col].nunique()\n",
    "        if unique_count <= 10:\n",
    "            low_cardinality.append(col)\n",
    "            print(f\"✓ {col}: One-Hot Encoding (cardinalidad: {unique_count})\")\n",
    "        else:\n",
    "            high_cardinality.append(col)\n",
    "            print(f\"✓ {col}: Label Encoding (cardinalidad: {unique_count})\")\n",
    "    \n",
    "    print(f\"\\nResumen:\")\n",
    "    print(f\"Variables para One-Hot Encoding: {len(low_cardinality)}\")\n",
    "    print(f\"Variables para Label Encoding: {len(high_cardinality)}\")\n",
    "else:\n",
    "    low_cardinality = []\n",
    "    high_cardinality = []\n",
    "    print(\"✓ No hay variables categóricas para codificar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55f4af8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APLICANDO CODIFICACIÓN\n",
      "==================================================\n",
      "Aplicando Label Encoding...\n",
      "  ✓ track_genre: 114 categorías → valores numéricos\n",
      "  ✓ key: 12 categorías → valores numéricos\n",
      "\n",
      "Aplicando One-Hot Encoding...\n",
      "  ✓ mode: 2 categorías → 1 variables dummy\n",
      "  ✓ time_signature: 5 categorías → 4 variables dummy\n",
      "\n",
      "✓ Codificación completada!\n",
      "✓ Forma después de normalización: (113999, 16)\n",
      "✓ Forma después de codificación: (113999, 19)\n",
      "✓ Nuevas características creadas: 3\n"
     ]
    }
   ],
   "source": [
    "# Aplicar codificación a variables categóricas\n",
    "df_encoded = df_normalized.copy()  # Usar el dataframe normalizado\n",
    "encoders = {}  # Diccionario para guardar los encoders\n",
    "\n",
    "print(\"APLICANDO CODIFICACIÓN\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Label Encoding para variables de alta cardinalidad\n",
    "if high_cardinality:\n",
    "    print(\"Aplicando Label Encoding...\")\n",
    "    for col in high_cardinality:\n",
    "        le = LabelEncoder()\n",
    "        df_encoded[col] = le.fit_transform(df_normalized[col].astype(str))\n",
    "        encoders[f'{col}_label_encoder'] = le\n",
    "        print(f\"  ✓ {col}: {df_normalized[col].nunique()} categorías → valores numéricos\")\n",
    "\n",
    "# One-Hot Encoding para variables de baja cardinalidad\n",
    "if low_cardinality:\n",
    "    print(\"\\nAplicando One-Hot Encoding...\")\n",
    "    for col in low_cardinality:\n",
    "        # Crear variables dummy\n",
    "        dummies = pd.get_dummies(df_normalized[col], prefix=col, drop_first=True)\n",
    "        \n",
    "        # Remover columna original y agregar las nuevas\n",
    "        df_encoded = df_encoded.drop(columns=[col])\n",
    "        df_encoded = pd.concat([df_encoded, dummies], axis=1)\n",
    "        \n",
    "        # Guardar las columnas creadas para referencia\n",
    "        encoders[f'{col}_dummy_columns'] = dummies.columns.tolist()\n",
    "        print(f\"  ✓ {col}: {df_normalized[col].nunique()} categorías → {len(dummies.columns)} variables dummy\")\n",
    "\n",
    "print(f\"\\n✓ Codificación completada!\")\n",
    "print(f\"✓ Forma después de normalización: {df_normalized.shape}\")\n",
    "print(f\"✓ Forma después de codificación: {df_encoded.shape}\")\n",
    "print(f\"✓ Nuevas características creadas: {df_encoded.shape[1] - df_normalized.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b802e73",
   "metadata": {},
   "source": [
    "## 6. División en Conjuntos de Entrenamiento y Prueba\n",
    "\n",
    "Dividir el conjunto de datos codificado en conjuntos de entrenamiento y prueba según los parámetros configurados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de4d8d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDENTIFICACIÓN DE VARIABLE OBJETIVO\n",
      "==================================================\n",
      "✓ Variable objetivo seleccionada: popularity\n",
      "\n",
      "Forma de características (X): (113999, 18)\n",
      "Forma de variable objetivo (y): (113999,)\n",
      "\n",
      "Distribución de la variable objetivo:\n",
      "popularity\n",
      "0      16019\n",
      "1       2140\n",
      "2       1036\n",
      "3        585\n",
      "4        389\n",
      "       ...  \n",
      "96         7\n",
      "97         8\n",
      "98         7\n",
      "99         1\n",
      "100        2\n",
      "Name: count, Length: 101, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar si existe una columna objetivo (target)\n",
    "print(\"IDENTIFICACIÓN DE VARIABLE OBJETIVO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "target_column = 'popularity'\n",
    "print(f\"✓ Variable objetivo seleccionada: {target_column}\")\n",
    "\n",
    "# Separar características (X) y variable objetivo (y)\n",
    "X = df_encoded.drop(columns=[target_column])\n",
    "y = df_encoded[target_column]\n",
    "\n",
    "print(f\"\\nForma de características (X): {X.shape}\")\n",
    "print(f\"Forma de variable objetivo (y): {y.shape}\")\n",
    "print(f\"\\nDistribución de la variable objetivo:\")\n",
    "print(y.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1f1e99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIVISIÓN EN CONJUNTOS DE ENTRENAMIENTO Y PRUEBA\n",
      "==================================================\n",
      "✓ División completada con semilla: 20250901\n",
      "✓ Tamaño de división de prueba: 20.0%\n",
      "\n",
      "Tamaños de conjuntos:\n",
      "  - Entrenamiento: 91,199 registros (80.0%)\n",
      "  - Prueba: 22,800 registros (20.0%)\n",
      "\n",
      "Distribución en conjunto de entrenamiento:\n",
      "popularity\n",
      "0      12783\n",
      "1       1713\n",
      "2        844\n",
      "3        458\n",
      "4        323\n",
      "       ...  \n",
      "96         6\n",
      "97         7\n",
      "98         6\n",
      "99         1\n",
      "100        2\n",
      "Name: count, Length: 101, dtype: int64\n",
      "\n",
      "Distribución en conjunto de prueba:\n",
      "popularity\n",
      "0     3236\n",
      "1      427\n",
      "2      192\n",
      "3      127\n",
      "4       66\n",
      "      ... \n",
      "92       2\n",
      "95       2\n",
      "96       1\n",
      "97       1\n",
      "98       1\n",
      "Name: count, Length: 97, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Realizar la división train/test\n",
    "print(\"DIVISIÓN EN CONJUNTOS DE ENTRENAMIENTO Y PRUEBA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=test_split, \n",
    "    random_state=random_seed,\n",
    "    #stratify=y if len(y.unique()) > 1 and len(y.unique()) < len(y) else None\n",
    ")\n",
    "\n",
    "print(f\"✓ División completada con semilla: {random_seed}\")\n",
    "print(f\"✓ Tamaño de división de prueba: {test_split*100}%\")\n",
    "print(f\"\\nTamaños de conjuntos:\")\n",
    "print(f\"  - Entrenamiento: {len(X_train):,} registros ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"  - Prueba: {len(X_test):,} registros ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nDistribución en conjunto de entrenamiento:\")\n",
    "print(y_train.value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nDistribución en conjunto de prueba:\")\n",
    "print(y_test.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87efe93a",
   "metadata": {},
   "source": [
    "## 7. Guardar Conjuntos de Datos Procesados\n",
    "\n",
    "Exportar los conjuntos de entrenamiento y prueba a los directorios especificados en la configuración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce0ff86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUARDANDO CONJUNTOS DE DATOS PROCESADOS\n",
      "==================================================\n",
      "✓ Directorios creados:\n",
      "  - Entrenamiento: ../data/train\n",
      "  - Prueba: ../data/test\n"
     ]
    }
   ],
   "source": [
    "# Crear directorios de salida\n",
    "print(\"GUARDANDO CONJUNTOS DE DATOS PROCESADOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "os.makedirs(output_path_train, exist_ok=True)\n",
    "os.makedirs(output_path_test, exist_ok=True)\n",
    "\n",
    "print(f\"✓ Directorios creados:\")\n",
    "print(f\"  - Entrenamiento: {output_path_train}\")\n",
    "print(f\"  - Prueba: {output_path_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08ae83ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Conjunto de entrenamiento guardado:\n",
      "  - Características: ../data/train/X_train.csv\n",
      "  - Variable objetivo: ../data/train/y_train.csv\n",
      "  - Registros: 91,199\n",
      "  - Características: 18\n"
     ]
    }
   ],
   "source": [
    "# Guardar conjunto de entrenamiento\n",
    "train_features_path = os.path.join(output_path_train, 'X_train.csv')\n",
    "train_target_path = os.path.join(output_path_train, 'y_train.csv')\n",
    "\n",
    "X_train.to_csv(train_features_path, index=False)\n",
    "y_train.to_csv(train_target_path, index=False)\n",
    "\n",
    "print(f\"✓ Conjunto de entrenamiento guardado:\")\n",
    "print(f\"  - Características: {train_features_path}\")\n",
    "print(f\"  - Variable objetivo: {train_target_path}\")\n",
    "print(f\"  - Registros: {len(X_train):,}\")\n",
    "print(f\"  - Características: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cf4e947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Conjunto de prueba guardado:\n",
      "  - Características: ../data/test/X_test.csv\n",
      "  - Variable objetivo: ../data/test/y_test.csv\n",
      "  - Registros: 22,800\n",
      "  - Características: 18\n"
     ]
    }
   ],
   "source": [
    "# Guardar conjunto de prueba\n",
    "test_features_path = os.path.join(output_path_test, 'X_test.csv')\n",
    "test_target_path = os.path.join(output_path_test, 'y_test.csv')\n",
    "\n",
    "X_test.to_csv(test_features_path, index=False)\n",
    "y_test.to_csv(test_target_path, index=False)\n",
    "\n",
    "print(f\"✓ Conjunto de prueba guardado:\")\n",
    "print(f\"  - Características: {test_features_path}\")\n",
    "print(f\"  - Variable objetivo: {test_target_path}\")\n",
    "print(f\"  - Registros: {len(X_test):,}\")\n",
    "print(f\"  - Características: {X_test.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "914d9a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Encoders guardados: ../data/train/encoders.joblib\n",
      "✓ Scalers guardados: ../data/train/scalers.joblib\n",
      "✓ Metadata guardada: ../data/train/metadata.yaml\n"
     ]
    }
   ],
   "source": [
    "# Guardar encoders, scalers y metadata\n",
    "encoders_path = os.path.join(output_path_train, 'encoders.joblib')\n",
    "scalers_path = os.path.join(output_path_train, 'scalers.joblib')\n",
    "metadata_path = os.path.join(output_path_train, 'metadata.yaml')\n",
    "\n",
    "# Guardar encoders\n",
    "if encoders:\n",
    "    joblib.dump(encoders, encoders_path)\n",
    "    print(f\"✓ Encoders guardados: {encoders_path}\")\n",
    "\n",
    "# Guardar scalers\n",
    "if scalers:\n",
    "    joblib.dump(scalers, scalers_path)\n",
    "    print(f\"✓ Scalers guardados: {scalers_path}\")\n",
    "\n",
    "# Crear metadata\n",
    "metadata = {\n",
    "    'original_shape': df.shape,\n",
    "    'encoded_shape': df_encoded.shape,\n",
    "    'target_column': target_column,\n",
    "    'numeric_columns': numeric_columns,\n",
    "    'categorical_columns': categorical_columns,\n",
    "    'low_cardinality_encoded': low_cardinality,\n",
    "    'high_cardinality_encoded': high_cardinality,\n",
    "    'train_size': len(X_train),\n",
    "    'test_size': len(X_test),\n",
    "    'test_split_ratio': test_split,\n",
    "    'random_seed': random_seed,\n",
    "    'feature_count': X_train.shape[1],\n",
    "    'encoding_date': datetime.now().strftime('%Y-%m-%d')\n",
    "}\n",
    "\n",
    "with open(metadata_path, 'w') as f:\n",
    "    yaml.dump(metadata, f, default_flow_style=False)\n",
    "\n",
    "print(f\"✓ Metadata guardada: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b976379",
   "metadata": {},
   "source": [
    "## 8. Resumen Final\n",
    "\n",
    "Resumen completo del proceso de preparación de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2fe8a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 PREPARACIÓN DE DATOS COMPLETADA EXITOSAMENTE\n",
      "============================================================\n",
      "📊 ESTADÍSTICAS GENERALES:\n",
      "  • Conjunto de datos original: (113999, 16)\n",
      "  • Conjunto de datos normalizado: (113999, 16)\n",
      "  • Conjunto de datos codificado: (113999, 19)\n",
      "  • Nuevas características creadas: 3\n",
      "\n",
      "🔧 PROCESAMIENTO REALIZADO:\n",
      "  • Variables numéricas: 11\n",
      "  • Variables normalizadas: 3\n",
      "  • Variables categóricas procesadas: 4\n",
      "  • One-Hot Encoding aplicado a: 2 variables\n",
      "  • Label Encoding aplicado a: 2 variables\n",
      "\n",
      "📏 NORMALIZACIÓN APLICADA:\n",
      "  • duration_ms: StandardScaler\n",
      "  • loudness: RobustScaler\n",
      "  • tempo: StandardScaler\n",
      "\n",
      "📁 DIVISIÓN DE DATOS:\n",
      "  • Conjunto de entrenamiento: 91,199 registros (80.0%)\n",
      "  • Conjunto de prueba: 22,800 registros (20.0%)\n",
      "  • Variable objetivo: popularity\n",
      "  • Semilla utilizada: 20250901\n",
      "\n",
      "💾 ARCHIVOS GENERADOS:\n",
      "  • ../data/train/X_train.csv\n",
      "  • ../data/train/y_train.csv\n",
      "  • ../data/test/X_test.csv\n",
      "  • ../data/test/y_test.csv\n",
      "  • ../data/train/encoders.joblib\n",
      "  • ../data/train/scalers.joblib\n",
      "  • ../data/train/metadata.yaml\n",
      "\n",
      "✅ Los datos están listos para el entrenamiento de modelos de machine learning!\n"
     ]
    }
   ],
   "source": [
    "# Resumen final del proceso\n",
    "print(\"🎉 PREPARACIÓN DE DATOS COMPLETADA EXITOSAMENTE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"📊 ESTADÍSTICAS GENERALES:\")\n",
    "print(f\"  • Conjunto de datos original: {df.shape}\")\n",
    "print(f\"  • Conjunto de datos normalizado: {df_normalized.shape}\")\n",
    "print(f\"  • Conjunto de datos codificado: {df_encoded.shape}\")\n",
    "print(f\"  • Nuevas características creadas: {df_encoded.shape[1] - df.shape[1]}\")\n",
    "\n",
    "print(f\"\\n🔧 PROCESAMIENTO REALIZADO:\")\n",
    "print(f\"  • Variables numéricas: {len(numeric_columns)}\")\n",
    "print(f\"  • Variables normalizadas: {len(variables_to_normalize)}\")\n",
    "print(f\"  • Variables categóricas procesadas: {len(categorical_columns)}\")\n",
    "print(f\"  • One-Hot Encoding aplicado a: {len(low_cardinality)} variables\")\n",
    "print(f\"  • Label Encoding aplicado a: {len(high_cardinality)} variables\")\n",
    "\n",
    "if variables_to_normalize:\n",
    "    print(f\"\\n📏 NORMALIZACIÓN APLICADA:\")\n",
    "    for col in variables_to_normalize:\n",
    "        method = normalization_strategy[col]['method']\n",
    "        print(f\"  • {col}: {method}\")\n",
    "\n",
    "print(f\"\\n📁 DIVISIÓN DE DATOS:\")\n",
    "print(f\"  • Conjunto de entrenamiento: {len(X_train):,} registros ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"  • Conjunto de prueba: {len(X_test):,} registros ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"  • Variable objetivo: {target_column}\")\n",
    "print(f\"  • Semilla utilizada: {random_seed}\")\n",
    "\n",
    "print(f\"\\n💾 ARCHIVOS GENERADOS:\")\n",
    "print(f\"  • {train_features_path}\")\n",
    "print(f\"  • {train_target_path}\")\n",
    "print(f\"  • {test_features_path}\")\n",
    "print(f\"  • {test_target_path}\")\n",
    "if encoders:\n",
    "    print(f\"  • {encoders_path}\")\n",
    "if scalers:\n",
    "    print(f\"  • {scalers_path}\")\n",
    "print(f\"  • {metadata_path}\")\n",
    "\n",
    "print(f\"\\n✅ Los datos están listos para el entrenamiento de modelos de machine learning!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
