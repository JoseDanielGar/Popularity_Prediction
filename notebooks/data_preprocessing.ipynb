{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385e97ab",
   "metadata": {},
   "source": [
    "# Preparaci√≥n de los datos\n",
    "\n",
    "En este notebook se realiza las siguientes acciones de limpieza de datos sobre el conjunto de datos base:\n",
    "\n",
    "- Cargar el conjunto de datos desde archivos .csv\n",
    "- Identificar y remover duplicados.\n",
    "- Identificar y remover registros con valores nulos.\n",
    "- Remover variables con informaci√≥n sensible o fuera del alcance en futuras etapas.\n",
    "- Verificaciones de calidad sobre el conjunto de datos de salida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9dfbe3",
   "metadata": {},
   "source": [
    "## 1. Importar librer√≠as requeridas\n",
    "\n",
    "Importar pandas y otras librer√≠as necesarias para la manipulaci√≥n y an√°lisis de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10600381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬°Bibliotecas importadas con √©xito!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import yaml\n",
    "\n",
    "# Suprimir los warnings para una salida m√°s limpia\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Opciones para una mejor visualizaci√≥n\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"¬°Bibliotecas importadas con √©xito!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5deb6af",
   "metadata": {},
   "source": [
    "## 2. Carga del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9325b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Dataset found at: ../data/raw/dataset.csv\n",
      "\n",
      "‚úì Dataset loaded successfully!\n",
      "Dataset shape: (114000, 21)\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the dataset\n",
    "config = yaml.safe_load(open(\"../params.yaml\"))[\"cleaning\"]\n",
    "dataset_path = \"../\" + config[\"input_path\"]\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(dataset_path):\n",
    "    print(f\"‚úì Dataset found at: {dataset_path}\")\n",
    "else:\n",
    "    print(f\"‚úó Dataset not found at: {dataset_path}\")\n",
    "    print(\"Please ensure the dataset.csv file is in the correct location.\")\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    print(f\"\\n‚úì Dataset loaded successfully!\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Error loading dataset: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c4fa8c",
   "metadata": {},
   "source": [
    "## 3. Exploraci√≥n de la estructura del conjunto de datos.\n",
    "\n",
    "Muestra informaci√≥n acerca del conjunto de datos cargado como son: forma, nombres de columnas, tipos de datos y estad√≠sticas generales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fff4ca26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Shape: (114000, 21)\n",
      "Total records: 114,000\n",
      "Total features: 21\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Store original dataset information for comparison\n",
    "original_shape = df.shape\n",
    "print(f\"Original Dataset Shape: {original_shape}\")\n",
    "print(f\"Total records: {original_shape[0]:,}\")\n",
    "print(f\"Total features: {original_shape[1]}\")\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "574a738a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5SuOikwiRyPMVoIQDJUgSV</td>\n",
       "      <td>Gen Hoshino</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>False</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.715</td>\n",
       "      <td>87.917</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4qPNDBW1i3p13qLCt0Ki3A</td>\n",
       "      <td>Ben Woodward</td>\n",
       "      <td>Ghost (Acoustic)</td>\n",
       "      <td>Ghost - Acoustic</td>\n",
       "      <td>55</td>\n",
       "      <td>149610</td>\n",
       "      <td>False</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>1</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.267</td>\n",
       "      <td>77.489</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1iJBSr7s7jYXzM8EGcbK5b</td>\n",
       "      <td>Ingrid Michaelson;ZAYN</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>57</td>\n",
       "      <td>210826</td>\n",
       "      <td>False</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.120</td>\n",
       "      <td>76.332</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6lfxq3CG4xtTiEg7opyCyx</td>\n",
       "      <td>Kina Grannis</td>\n",
       "      <td>Crazy Rich Asians (Original Motion Picture Sou...</td>\n",
       "      <td>Can't Help Falling In Love</td>\n",
       "      <td>71</td>\n",
       "      <td>201933</td>\n",
       "      <td>False</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.143</td>\n",
       "      <td>181.740</td>\n",
       "      <td>3</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5vjLSffimiIP26QG5WcN2K</td>\n",
       "      <td>Chord Overstreet</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>82</td>\n",
       "      <td>198853</td>\n",
       "      <td>False</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.167</td>\n",
       "      <td>119.949</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                track_id                 artists  \\\n",
       "0      0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n",
       "1      1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n",
       "2      2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n",
       "3      3  6lfxq3CG4xtTiEg7opyCyx            Kina Grannis   \n",
       "4      4  5vjLSffimiIP26QG5WcN2K        Chord Overstreet   \n",
       "\n",
       "                                          album_name  \\\n",
       "0                                             Comedy   \n",
       "1                                   Ghost (Acoustic)   \n",
       "2                                     To Begin Again   \n",
       "3  Crazy Rich Asians (Original Motion Picture Sou...   \n",
       "4                                            Hold On   \n",
       "\n",
       "                   track_name  popularity  duration_ms  explicit  \\\n",
       "0                      Comedy          73       230666     False   \n",
       "1            Ghost - Acoustic          55       149610     False   \n",
       "2              To Begin Again          57       210826     False   \n",
       "3  Can't Help Falling In Love          71       201933     False   \n",
       "4                     Hold On          82       198853     False   \n",
       "\n",
       "   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.676  0.4610    1    -6.746     0       0.1430        0.0322   \n",
       "1         0.420  0.1660    1   -17.235     1       0.0763        0.9240   \n",
       "2         0.438  0.3590    0    -9.734     1       0.0557        0.2100   \n",
       "3         0.266  0.0596    0   -18.515     1       0.0363        0.9050   \n",
       "4         0.618  0.4430    2    -9.681     1       0.0526        0.4690   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  time_signature track_genre  \n",
       "0          0.000001    0.3580    0.715   87.917               4    acoustic  \n",
       "1          0.000006    0.1010    0.267   77.489               4    acoustic  \n",
       "2          0.000000    0.1170    0.120   76.332               4    acoustic  \n",
       "3          0.000071    0.1320    0.143  181.740               3    acoustic  \n",
       "4          0.000000    0.0829    0.167  119.949               4    acoustic  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(\"=\"*50)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dad17c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "==================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114000 entries, 0 to 113999\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   index             114000 non-null  int64  \n",
      " 1   track_id          114000 non-null  object \n",
      " 2   artists           113999 non-null  object \n",
      " 3   album_name        113999 non-null  object \n",
      " 4   track_name        113999 non-null  object \n",
      " 5   popularity        114000 non-null  int64  \n",
      " 6   duration_ms       114000 non-null  int64  \n",
      " 7   explicit          114000 non-null  bool   \n",
      " 8   danceability      114000 non-null  float64\n",
      " 9   energy            114000 non-null  float64\n",
      " 10  key               114000 non-null  int64  \n",
      " 11  loudness          114000 non-null  float64\n",
      " 12  mode              114000 non-null  int64  \n",
      " 13  speechiness       114000 non-null  float64\n",
      " 14  acousticness      114000 non-null  float64\n",
      " 15  instrumentalness  114000 non-null  float64\n",
      " 16  liveness          114000 non-null  float64\n",
      " 17  valence           114000 non-null  float64\n",
      " 18  tempo             114000 non-null  float64\n",
      " 19  time_signature    114000 non-null  int64  \n",
      " 20  track_genre       114000 non-null  object \n",
      "dtypes: bool(1), float64(9), int64(6), object(5)\n",
      "memory usage: 17.5+ MB\n",
      "None\n",
      "\n",
      "Column names:\n",
      "['index', 'track_id', 'artists', 'album_name', 'track_name', 'popularity', 'duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'track_genre']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114000 entries, 0 to 113999\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   index             114000 non-null  int64  \n",
      " 1   track_id          114000 non-null  object \n",
      " 2   artists           113999 non-null  object \n",
      " 3   album_name        113999 non-null  object \n",
      " 4   track_name        113999 non-null  object \n",
      " 5   popularity        114000 non-null  int64  \n",
      " 6   duration_ms       114000 non-null  int64  \n",
      " 7   explicit          114000 non-null  bool   \n",
      " 8   danceability      114000 non-null  float64\n",
      " 9   energy            114000 non-null  float64\n",
      " 10  key               114000 non-null  int64  \n",
      " 11  loudness          114000 non-null  float64\n",
      " 12  mode              114000 non-null  int64  \n",
      " 13  speechiness       114000 non-null  float64\n",
      " 14  acousticness      114000 non-null  float64\n",
      " 15  instrumentalness  114000 non-null  float64\n",
      " 16  liveness          114000 non-null  float64\n",
      " 17  valence           114000 non-null  float64\n",
      " 18  tempo             114000 non-null  float64\n",
      " 19  time_signature    114000 non-null  int64  \n",
      " 20  track_genre       114000 non-null  object \n",
      "dtypes: bool(1), float64(9), int64(6), object(5)\n",
      "memory usage: 17.5+ MB\n",
      "None\n",
      "\n",
      "Column names:\n",
      "['index', 'track_id', 'artists', 'album_name', 'track_name', 'popularity', 'duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'track_genre']\n"
     ]
    }
   ],
   "source": [
    "# Display dataset information\n",
    "print(\"Dataset Information:\")\n",
    "print(\"=\"*50)\n",
    "print(df.info())\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1ec1b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Analysis:\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>artists</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>album_name</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>track_name</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Column  Missing Count  Missing Percentage\n",
       "2     artists              1            0.000877\n",
       "3  album_name              1            0.000877\n",
       "4  track_name              1            0.000877"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total missing values: 3\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values Analysis:\")\n",
    "print(\"=\"*50)\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing_values.index,\n",
    "    'Missing Count': missing_values.values,\n",
    "    'Missing Percentage': missing_percentage.values\n",
    "})\n",
    "\n",
    "# Show only columns with missing values\n",
    "missing_with_nulls = missing_df[missing_df['Missing Count'] > 0]\n",
    "if len(missing_with_nulls) > 0:\n",
    "    display(missing_with_nulls)\n",
    "else:\n",
    "    print(\"‚úì No missing values found in the dataset!\")\n",
    "\n",
    "print(f\"\\nTotal missing values: {missing_values.sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4df15e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Records Analysis:\n",
      "==================================================\n",
      "Number of duplicate records: 0\n",
      "Percentage of duplicate records: 0.00%\n",
      "‚úì No duplicate records found!\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate records\n",
    "print(\"Duplicate Records Analysis:\")\n",
    "print(\"=\"*50)\n",
    "duplicate_count = df.duplicated().sum()\n",
    "duplicate_percentage = (duplicate_count / len(df)) * 100\n",
    "\n",
    "print(f\"Number of duplicate records: {duplicate_count:,}\")\n",
    "print(f\"Percentage of duplicate records: {duplicate_percentage:.2f}%\")\n",
    "\n",
    "if duplicate_count > 0:\n",
    "    print(\"\\nExample of duplicate records:\")\n",
    "    duplicates = df[df.duplicated(keep=False)]\n",
    "    display(duplicates.head(10))\n",
    "else:\n",
    "    print(\"‚úì No duplicate records found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0365d6e",
   "metadata": {},
   "source": [
    "## 4. Remover registros duplicados\n",
    "\n",
    "Identificar y remover los registros duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a4a1ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing Duplicate Records...\n",
      "==================================================\n",
      "Duplicates before removal: 0\n",
      "Duplicates after removal: 0\n",
      "Records removed: 0\n",
      "‚úì No duplicate records found to remove.\n",
      "Duplicates after removal: 0\n",
      "Records removed: 0\n",
      "‚úì No duplicate records found to remove.\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate records\n",
    "print(\"Removing Duplicate Records...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Count duplicates before removal\n",
    "duplicates_before = df.duplicated().sum()\n",
    "print(f\"Duplicates before removal: {duplicates_before:,}\")\n",
    "\n",
    "# Remove duplicates\n",
    "df_cleaned = df.drop_duplicates()\n",
    "\n",
    "# Count duplicates after removal\n",
    "duplicates_after = df_cleaned.duplicated().sum()\n",
    "records_removed = len(df) - len(df_cleaned)\n",
    "\n",
    "print(f\"Duplicates after removal: {duplicates_after:,}\")\n",
    "print(f\"Records removed: {records_removed:,}\")\n",
    "\n",
    "if records_removed > 0:\n",
    "    print(f\"‚úì Successfully removed {records_removed:,} duplicate records!\")\n",
    "else:\n",
    "    print(\"‚úì No duplicate records found to remove.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a21277",
   "metadata": {},
   "source": [
    "## 5. Remover valores faltantes.\n",
    "\n",
    "Identificar los registros con valores faltantes y removerlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c7fb9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing Records with Missing Values...\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values before removal: 3\n",
      "Records with at least one missing value: 1\n",
      "\n",
      "Total missing values after removal: 0\n",
      "Records with missing values after removal: 0\n",
      "Records removed due to missing values: 1\n",
      "‚úì Successfully removed 1 records with missing values!\n",
      "\n",
      "Total missing values after removal: 0\n",
      "Records with missing values after removal: 0\n",
      "Records removed due to missing values: 1\n",
      "‚úì Successfully removed 1 records with missing values!\n"
     ]
    }
   ],
   "source": [
    "# Remove records with missing values\n",
    "print(\"Removing Records with Missing Values...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Count missing values before removal\n",
    "missing_before = df_cleaned.isnull().sum().sum()\n",
    "records_with_nulls_before = df_cleaned.isnull().any(axis=1).sum()\n",
    "\n",
    "print(f\"Total missing values before removal: {missing_before:,}\")\n",
    "print(f\"Records with at least one missing value: {records_with_nulls_before:,}\")\n",
    "\n",
    "# Remove records with any missing values\n",
    "df_final = df_cleaned.dropna()\n",
    "\n",
    "# Count missing values after removal\n",
    "missing_after = df_final.isnull().sum().sum()\n",
    "records_with_nulls_after = df_final.isnull().any(axis=1).sum()\n",
    "null_records_removed = len(df_cleaned) - len(df_final)\n",
    "\n",
    "print(f\"\\nTotal missing values after removal: {missing_after:,}\")\n",
    "print(f\"Records with missing values after removal: {records_with_nulls_after:,}\")\n",
    "print(f\"Records removed due to missing values: {null_records_removed:,}\")\n",
    "\n",
    "if null_records_removed > 0:\n",
    "    print(f\"‚úì Successfully removed {null_records_removed:,} records with missing values!\")\n",
    "else:\n",
    "    print(\"‚úì No records with missing values found to remove.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a454d6db",
   "metadata": {},
   "source": [
    "# 6. Remover varaibles que no ser√°n usadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68b7dd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing columns: ['index', 'track_id', 'artists', 'album_name', 'track_name']\n",
      "Columns found and will be removed: ['index', 'track_id', 'artists', 'album_name', 'track_name']\n",
      "‚úì Successfully removed 5 columns\n",
      "Shape after column removal: (113999, 16)\n",
      "Remaining columns: ['popularity', 'duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'track_genre']\n"
     ]
    }
   ],
   "source": [
    "# Remove specified columns before saving\n",
    "columns_to_remove = ['index', 'track_id', 'artists', 'album_name', 'track_name']\n",
    "print(f\"Removing columns: {columns_to_remove}\")\n",
    "\n",
    "# Check which columns exist in the dataset\n",
    "existing_columns_to_remove = [col for col in columns_to_remove if col in df_final.columns]\n",
    "missing_columns = [col for col in columns_to_remove if col not in df_final.columns]\n",
    "\n",
    "if existing_columns_to_remove:\n",
    "    print(f\"Columns found and will be removed: {existing_columns_to_remove}\")\n",
    "    df_final_for_saving = df_final.drop(columns=existing_columns_to_remove)\n",
    "    print(f\"‚úì Successfully removed {len(existing_columns_to_remove)} columns\")\n",
    "else:\n",
    "    df_final_for_saving = df_final.copy()\n",
    "    print(\"‚úì No specified columns found to remove\")\n",
    "\n",
    "if missing_columns:\n",
    "    print(f\"Columns not found in dataset: {missing_columns}\")\n",
    "\n",
    "print(f\"Shape after column removal: {df_final_for_saving.shape}\")\n",
    "print(f\"Remaining columns: {list(df_final_for_saving.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d836464",
   "metadata": {},
   "source": [
    "## 7. Revisar los resultados de la limpieza.\n",
    "\n",
    "Muestra el resultados final de la limpieza y compara el antes y despu√©s para verificar que haya sido existosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf7dde19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA CLEANING SUMMARY\n",
      "============================================================\n",
      "Original dataset shape: (114000, 21)\n",
      "Final dataset shape: (113999, 21)\n",
      "\n",
      "Records removed: 1 (0.00%)\n",
      "Records retained: 113,999 (100.00%)\n",
      "\n",
      "Breakdown of records removed:\n",
      "  - Duplicate records: 0\n",
      "  - Records with missing values: 1\n",
      "  - Total removed: 1\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive cleaning summary\n",
    "print(\"DATA CLEANING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate total records removed\n",
    "total_records_removed = len(df) - len(df_final)\n",
    "percentage_removed = (total_records_removed / len(df)) * 100\n",
    "percentage_retained = ((len(df_final)) / len(df)) * 100\n",
    "\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"Final dataset shape: {df_final.shape}\")\n",
    "print(f\"\\nRecords removed: {total_records_removed:,} ({percentage_removed:.2f}%)\")\n",
    "print(f\"Records retained: {len(df_final):,} ({percentage_retained:.2f}%)\")\n",
    "\n",
    "print(f\"\\nBreakdown of records removed:\")\n",
    "print(f\"  - Duplicate records: {records_removed:,}\")\n",
    "print(f\"  - Records with missing values: {null_records_removed:,}\")\n",
    "print(f\"  - Total removed: {total_records_removed:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2183ffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL DATASET QUALITY CHECK\n",
      "============================================================\n",
      "Duplicate records in final dataset: 0\n",
      "Missing values in final dataset: 0\n",
      "\n",
      "‚úÖ DATA CLEANING SUCCESSFUL!\n",
      "‚úì No duplicate records\n",
      "‚úì No missing values\n",
      "‚úì Dataset is ready for analysis and modeling\n"
     ]
    }
   ],
   "source": [
    "# Verify final dataset quality\n",
    "print(\"FINAL DATASET QUALITY CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check for duplicates in final dataset\n",
    "final_duplicates = df_final.duplicated().sum()\n",
    "print(f\"Duplicate records in final dataset: {final_duplicates:,}\")\n",
    "\n",
    "# Check for missing values in final dataset\n",
    "final_missing = df_final.isnull().sum().sum()\n",
    "print(f\"Missing values in final dataset: {final_missing:,}\")\n",
    "\n",
    "# Data quality status\n",
    "if final_duplicates == 0 and final_missing == 0:\n",
    "    print(\"\\n‚úÖ DATA CLEANING SUCCESSFUL!\")\n",
    "    print(\"‚úì No duplicate records\")\n",
    "    print(\"‚úì No missing values\")\n",
    "    print(\"‚úì Dataset is ready for analysis and modeling\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è WARNING: Data cleaning may not be complete\")\n",
    "    if final_duplicates > 0:\n",
    "        print(f\"‚ö†Ô∏è Still {final_duplicates:,} duplicate records remain\")\n",
    "    if final_missing > 0:\n",
    "        print(f\"‚ö†Ô∏è Still {final_missing:,} missing values remain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1960f7d1",
   "metadata": {},
   "source": [
    "## 8. Guardar el conjunto de datos limpio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c3abaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVE CLEANED DATASET\n",
      "============================================================\n",
      "\n",
      "‚úì Cleaned dataset saved to: ../data/prep/dataset_cleaned.csv\n",
      "‚úì File size: 10,058,238 bytes\n",
      "‚úì Records saved: 113,999\n",
      "‚úì Features saved: 16\n",
      "\n",
      "üéâ Data preprocessing completed successfully!\n",
      "\n",
      "‚úì Cleaned dataset saved to: ../data/prep/dataset_cleaned.csv\n",
      "‚úì File size: 10,058,238 bytes\n",
      "‚úì Records saved: 113,999\n",
      "‚úì Features saved: 16\n",
      "\n",
      "üéâ Data preprocessing completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Optional: Save the cleaned dataset\n",
    "print(\"SAVE CLEANED DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = \"../\" + config[\"output_path\"]\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "output_path = os.path.join(output_dir, 'dataset_cleaned.csv')\n",
    "df_final_for_saving.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n‚úì Cleaned dataset saved to: {output_path}\")\n",
    "print(f\"‚úì File size: {os.path.getsize(output_path):,} bytes\")\n",
    "print(f\"‚úì Records saved: {len(df_final_for_saving):,}\")\n",
    "print(f\"‚úì Features saved: {len(df_final_for_saving.columns)}\")\n",
    "\n",
    "print(\"\\nüéâ Data preprocessing completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4090fbcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
