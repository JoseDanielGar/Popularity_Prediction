{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "761d9f23",
   "metadata": {},
   "source": [
    "# B√∫squeda de Hiperpar√°metros con SGDRegressor\n",
    "\n",
    "Este notebook realiza la b√∫squeda de hiperpar√°metros para un modelo SGDRegressor (Stochastic Gradient Descent Regressor) con las siguientes caracter√≠sticas:\n",
    "\n",
    "- Carga de datos de entrenamiento desde archivos CSV\n",
    "- B√∫squeda de hiperpar√°metros con Grid Search\n",
    "- Validaci√≥n cruzada para evaluaci√≥n robusta\n",
    "- Divisi√≥n para validaci√≥n (15% del conjunto de entrenamiento)\n",
    "- Visualizaci√≥n de m√©tricas de regresi√≥n para los mejores modelos\n",
    "- An√°lisis comparativo de los top 3 modelos\n",
    "\n",
    "**Autor:** ML Engineer  \n",
    "**Fecha:** 6 de Septiembre, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b698c81",
   "metadata": {},
   "source": [
    "## 1. Importar Librer√≠as Requeridas\n",
    "\n",
    "Importar todas las librer√≠as necesarias para el an√°lisis, modelado y visualizaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a89a83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Librer√≠as importadas exitosamente!\n",
      "Pandas versi√≥n: 2.3.2\n",
      "NumPy versi√≥n: 2.3.2\n",
      "Scikit-learn disponible para GridSearchCV y SGDRegressor\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV, \n",
    "    train_test_split, \n",
    "    cross_val_score, \n",
    "    StratifiedShuffleSplit\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, \n",
    "    mean_absolute_error, \n",
    "    r2_score, \n",
    "    explained_variance_score,\n",
    "    accuracy_score\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"‚úì Librer√≠as importadas exitosamente!\")\n",
    "print(f\"Pandas versi√≥n: {pd.__version__}\")\n",
    "print(f\"NumPy versi√≥n: {np.__version__}\")\n",
    "print(f\"Scikit-learn disponible para GridSearchCV y SGDRegressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965b52a5",
   "metadata": {},
   "source": [
    "## 2. Cargar Datos de Entrenamiento\n",
    "\n",
    "Cargar las caracter√≠sticas y variables objetivo desde los archivos CSV generados en el proceso de preparaci√≥n de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b1d44e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARGA DE DATOS DE ENTRENAMIENTO\n",
      "==================================================\n",
      "‚úì Caracter√≠sticas cargadas desde: ../data/train/X_train.csv\n",
      "  ‚Ä¢ Forma: (91199, 18)\n",
      "  ‚Ä¢ Caracter√≠sticas: 18\n",
      "‚úì Variable objetivo cargada desde: ../data/train/y_train.csv\n",
      "  ‚Ä¢ Forma: (91199,)\n",
      "\n",
      "‚úì Datos cargados exitosamente!\n",
      "Total de registros: 91,199\n"
     ]
    }
   ],
   "source": [
    "# Definir rutas de los archivos\n",
    "X_train_path = '../data/train/X_train.csv'\n",
    "y_train_path = '../data/train/y_train.csv'\n",
    "\n",
    "print(\"CARGA DE DATOS DE ENTRENAMIENTO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Cargar caracter√≠sticas (X_train)\n",
    "try:\n",
    "    X_train_full = pd.read_csv(X_train_path)\n",
    "    print(f\"‚úì Caracter√≠sticas cargadas desde: {X_train_path}\")\n",
    "    print(f\"  ‚Ä¢ Forma: {X_train_full.shape}\")\n",
    "    print(f\"  ‚Ä¢ Caracter√≠sticas: {X_train_full.shape[1]}\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"Archivo no encontrado: {X_train_path}\")\n",
    "\n",
    "# Cargar variable objetivo (y_train)\n",
    "try:\n",
    "    y_train_full = pd.read_csv(y_train_path)\n",
    "    # Si es un DataFrame con una columna, convertir a Series\n",
    "    if isinstance(y_train_full, pd.DataFrame):\n",
    "        y_train_full = y_train_full.iloc[:, 0]\n",
    "    print(f\"‚úì Variable objetivo cargada desde: {y_train_path}\")\n",
    "    print(f\"  ‚Ä¢ Forma: {y_train_full.shape}\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"Archivo no encontrado: {y_train_path}\")\n",
    "\n",
    "print(f\"\\n‚úì Datos cargados exitosamente!\")\n",
    "print(f\"Total de registros: {len(X_train_full):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027b193b",
   "metadata": {},
   "source": [
    "## 3. Divisi√≥n para Validaci√≥n\n",
    "\n",
    "Crear una divisi√≥n del 15% del conjunto de entrenamiento para validaci√≥n final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48d2c86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIVISI√ìN PARA VALIDACI√ìN\n",
      "==================================================\n",
      "Divisi√≥n completada:\n",
      "  ‚Ä¢ Conjunto de entrenamiento: 77,519 registros (85%)\n",
      "  ‚Ä¢ Conjunto de validaci√≥n: 13,680 registros (15%)\n",
      "\n",
      "Estad√≠sticas del conjunto de entrenamiento:\n",
      "  ‚Ä¢ Media: 33.2631\n",
      "  ‚Ä¢ Desviaci√≥n est√°ndar: 22.3362\n",
      "  ‚Ä¢ Rango: [0, 100]\n",
      "\n",
      "Estad√≠sticas del conjunto de validaci√≥n:\n",
      "  ‚Ä¢ Media: 33.4199\n",
      "  ‚Ä¢ Desviaci√≥n est√°ndar: 22.2555\n",
      "  ‚Ä¢ Rango: [0, 100]\n",
      "\n",
      "‚úì Divisi√≥n completada exitosamente!\n"
     ]
    }
   ],
   "source": [
    "# Divisi√≥n para validaci√≥n (15% del dataset)\n",
    "print(\"DIVISI√ìN PARA VALIDACI√ìN\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "validation_size = 0.15\n",
    "random_state = 42\n",
    "\n",
    "# Realizar la divisi√≥n\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, \n",
    "    y_train_full, \n",
    "    test_size=validation_size, \n",
    "    random_state=random_state,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Divisi√≥n completada:\")\n",
    "print(f\"  ‚Ä¢ Conjunto de entrenamiento: {len(X_train):,} registros ({(1-validation_size)*100:.0f}%)\")\n",
    "print(f\"  ‚Ä¢ Conjunto de validaci√≥n: {len(X_val):,} registros ({validation_size*100:.0f}%)\")\n",
    "\n",
    "# Verificar las estad√≠sticas en ambos conjuntos\n",
    "print(f\"\\nEstad√≠sticas del conjunto de entrenamiento:\")\n",
    "print(f\"  ‚Ä¢ Media: {y_train.mean():.4f}\")\n",
    "print(f\"  ‚Ä¢ Desviaci√≥n est√°ndar: {y_train.std():.4f}\")\n",
    "print(f\"  ‚Ä¢ Rango: [{y_train.min()}, {y_train.max()}]\")\n",
    "\n",
    "print(f\"\\nEstad√≠sticas del conjunto de validaci√≥n:\")\n",
    "print(f\"  ‚Ä¢ Media: {y_val.mean():.4f}\")\n",
    "print(f\"  ‚Ä¢ Desviaci√≥n est√°ndar: {y_val.std():.4f}\")\n",
    "print(f\"  ‚Ä¢ Rango: [{y_val.min()}, {y_val.max()}]\")\n",
    "\n",
    "print(f\"\\n‚úì Divisi√≥n completada exitosamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91def881",
   "metadata": {},
   "source": [
    "## 5. Configuraci√≥n de B√∫squeda de Hiperpar√°metros\n",
    "\n",
    "Definir la grilla de hiperpar√°metros y configurar GridSearchCV para SGDRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e88e79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIGURACI√ìN DE GRILLA DE HIPERPAR√ÅMETROS\n",
      "==================================================\n",
      "Grilla de hiperpar√°metros definida:\n",
      "  ‚Ä¢ loss: ['squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive']\n",
      "  ‚Ä¢ penalty: ['l2', 'l1', 'elasticnet']\n",
      "  ‚Ä¢ alpha: [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
      "  ‚Ä¢ l1_ratio: [0.15, 0.5, 0.7, 0.9]\n",
      "  ‚Ä¢ learning_rate: ['constant', 'optimal', 'invscaling', 'adaptive']\n",
      "  ‚Ä¢ eta0: [0.001, 0.01, 0.1, 1.0]\n",
      "  ‚Ä¢ max_iter: [1000, 5000, 10000]\n",
      "\n",
      "Total de combinaciones: 11,520\n",
      "‚ö†Ô∏è Nota: Algunas combinaciones pueden no ser v√°lidas (ej: l1_ratio solo aplica para elasticnet)\n",
      "Validaci√≥n cruzada: 5 folds\n",
      "Estimaci√≥n de entrenamientos: ~14,400 (considerando combinaciones v√°lidas)\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n de la grilla de hiperpar√°metros para SGDRegressor\n",
    "print(\"CONFIGURACI√ìN DE GRILLA DE HIPERPAR√ÅMETROS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Definir la grilla de hiperpar√°metros\n",
    "param_grid = {\n",
    "    'loss': ['squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0],  # Par√°metro de regularizaci√≥n\n",
    "    'l1_ratio': [0.15, 0.5, 0.7, 0.9],  # Solo para elasticnet\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "    'eta0': [0.001, 0.01, 0.1, 1.0],  # Tasa de aprendizaje inicial\n",
    "    'max_iter': [1000, 5000, 10000]\n",
    "}\n",
    "\n",
    "print(f\"Grilla de hiperpar√°metros definida:\")\n",
    "total_combinations = 1\n",
    "for param, values in param_grid.items():\n",
    "    print(f\"  ‚Ä¢ {param}: {values}\")\n",
    "    total_combinations *= len(values)\n",
    "\n",
    "print(f\"\\nTotal de combinaciones: {total_combinations:,}\")\n",
    "print(f\"‚ö†Ô∏è Nota: Algunas combinaciones pueden no ser v√°lidas (ej: l1_ratio solo aplica para elasticnet)\")\n",
    "\n",
    "# Configurar validaci√≥n cruzada\n",
    "cv_folds = 5\n",
    "print(f\"Validaci√≥n cruzada: {cv_folds} folds\")\n",
    "print(f\"Estimaci√≥n de entrenamientos: ~{total_combinations * cv_folds // 4:,} (considerando combinaciones v√°lidas)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b3787f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIGURACI√ìN DE GRIDSEARCHCV\n",
      "==================================================\n",
      "‚úì GridSearchCV configurado:\n",
      "  ‚Ä¢ Estimador: SGDRegressor\n",
      "  ‚Ä¢ M√©trica de scoring: neg_mean_squared_error\n",
      "  ‚Ä¢ Folds de CV: 5\n",
      "  ‚Ä¢ Paralelizaci√≥n: Todos los cores disponibles\n",
      "  ‚Ä¢ Tolerancia: 1e-3\n",
      "\n",
      "üöÄ Listo para ejecutar b√∫squeda de hiperpar√°metros...\n"
     ]
    }
   ],
   "source": [
    "# Configurar GridSearchCV\n",
    "print(\"CONFIGURACI√ìN DE GRIDSEARCHCV\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Crear el modelo base\n",
    "sgd_model = SGDRegressor(random_state=42, tol=1e-3)\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=sgd_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv_folds,\n",
    "    scoring='neg_mean_squared_error',  # M√©trica principal para optimizaci√≥n\n",
    "    n_jobs=-1,  # Usar todos los cores disponibles\n",
    "    verbose=1,  # Mostrar progreso\n",
    "    return_train_score=True,\n",
    "    error_score='raise'  # Lanzar error si hay problemas\n",
    ")\n",
    "\n",
    "print(f\"‚úì GridSearchCV configurado:\")\n",
    "print(f\"  ‚Ä¢ Estimador: SGDRegressor\")\n",
    "print(f\"  ‚Ä¢ M√©trica de scoring: neg_mean_squared_error\")\n",
    "print(f\"  ‚Ä¢ Folds de CV: {cv_folds}\")\n",
    "print(f\"  ‚Ä¢ Paralelizaci√≥n: Todos los cores disponibles\")\n",
    "print(f\"  ‚Ä¢ Tolerancia: 1e-3\")\n",
    "\n",
    "print(f\"\\nüöÄ Listo para ejecutar b√∫squeda de hiperpar√°metros...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cdeea9",
   "metadata": {},
   "source": [
    "## 6. Ejecuci√≥n de B√∫squeda de Hiperpar√°metros\n",
    "\n",
    "Ejecutar GridSearchCV para encontrar los mejores hiperpar√°metros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca8d8dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç INICIANDO B√öSQUEDA DE HIPERPAR√ÅMETROS\n",
      "==================================================\n",
      "Inicio: 2025-09-06 13:06:59\n",
      "Esto puede tomar varios minutos...\n",
      "\n",
      "Fitting 5 folds for each of 11520 candidates, totalling 57600 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m start_time = datetime.now()\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     end_time = datetime.now()\n\u001b[32m     13\u001b[39m     duration = end_time - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/personal/uniandes/Popularity_Prediction/.venv/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/personal/uniandes/Popularity_Prediction/.venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/personal/uniandes/Popularity_Prediction/.venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/personal/uniandes/Popularity_Prediction/.venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/personal/uniandes/Popularity_Prediction/.venv/lib/python3.13/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/personal/uniandes/Popularity_Prediction/.venv/lib/python3.13/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/personal/uniandes/Popularity_Prediction/.venv/lib/python3.13/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/personal/uniandes/Popularity_Prediction/.venv/lib/python3.13/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Ejecutar b√∫squeda de hiperpar√°metros\n",
    "print(\"üîç INICIANDO B√öSQUEDA DE HIPERPAR√ÅMETROS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Inicio: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"Esto puede tomar varios minutos...\\n\")\n",
    "\n",
    "# Ejecutar grid search\n",
    "start_time = datetime.now()\n",
    "\n",
    "try:\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    end_time = datetime.now()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(f\"\\n‚úì B√∫squeda de hiperpar√°metros completada!\")\n",
    "    print(f\"Tiempo total: {duration}\")\n",
    "    print(f\"Fin: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error durante la b√∫squeda: {e}\")\n",
    "    print(\"Reintentando con configuraci√≥n m√°s conservadora...\")\n",
    "    \n",
    "    # Configuraci√≥n m√°s conservadora si hay errores\n",
    "    conservative_param_grid = {\n",
    "        'loss': ['squared_error', 'huber'],\n",
    "        'penalty': ['l2', 'l1'],\n",
    "        'alpha': [0.001, 0.01, 0.1],\n",
    "        'learning_rate': ['optimal', 'constant'],\n",
    "        'eta0': [0.01, 0.1],\n",
    "        'max_iter': [5000, 10000]\n",
    "    }\n",
    "    \n",
    "    grid_search_conservative = GridSearchCV(\n",
    "        estimator=sgd_model,\n",
    "        param_grid=conservative_param_grid,\n",
    "        cv=cv_folds,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        return_train_score=True\n",
    "    )\n",
    "    \n",
    "    grid_search_conservative.fit(X_train, y_train)\n",
    "    grid_search = grid_search_conservative  # Usar el resultado conservador\n",
    "    end_time = datetime.now()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(f\"\\n‚úì B√∫squeda completada con configuraci√≥n conservadora!\")\n",
    "    print(f\"Tiempo total: {duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593cabcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar resultados de la b√∫squeda\n",
    "print(\"RESULTADOS DE LA B√öSQUEDA DE HIPERPAR√ÅMETROS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Mejores hiperpar√°metros\n",
    "print(f\"Mejores hiperpar√°metros encontrados:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  ‚Ä¢ {param}: {value}\")\n",
    "\n",
    "print(f\"\\nMejor score (CV): {-grid_search.best_score_:.6f} (MSE)\")\n",
    "print(f\"RMSE del mejor modelo: {np.sqrt(-grid_search.best_score_):.6f}\")\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"\\n‚úì Mejor modelo obtenido y listo para evaluaci√≥n\")\n",
    "\n",
    "# Informaci√≥n adicional sobre convergencia\n",
    "print(f\"\\nInformaci√≥n del mejor modelo:\")\n",
    "print(f\"  ‚Ä¢ Iteraciones hasta convergencia: {best_model.n_iter_}\")\n",
    "print(f\"  ‚Ä¢ Coeficientes activos: {np.count_nonzero(best_model.coef_)} de {len(best_model.coef_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f7eba1",
   "metadata": {},
   "source": [
    "## 7. An√°lisis de los Top 3 Modelos\n",
    "\n",
    "Analizar y comparar las m√©tricas de los 3 mejores modelos encontrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb0ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los top 3 modelos\n",
    "print(\"AN√ÅLISIS DE LOS TOP 3 MODELOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Crear DataFrame con todos los resultados\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Ordenar por mejor score y obtener top 3\n",
    "top_3_results = results_df.nlargest(3, 'mean_test_score')\n",
    "\n",
    "print(f\"Top 3 configuraciones de hiperpar√°metros:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "top_3_models = []\n",
    "top_3_params = []\n",
    "\n",
    "for i, (idx, row) in enumerate(top_3_results.iterrows(), 1):\n",
    "    params = row['params']\n",
    "    score = row['mean_test_score']\n",
    "    std = row['std_test_score']\n",
    "    \n",
    "    print(f\"\\nModelo #{i}:\")\n",
    "    print(f\"  MSE Score: {-score:.6f} (¬±{std:.6f})\")\n",
    "    print(f\"  RMSE: {np.sqrt(-score):.6f}\")\n",
    "    print(f\"  Par√°metros: {params}\")\n",
    "    \n",
    "    # Crear y entrenar el modelo con estos par√°metros\n",
    "    model = SGDRegressor(random_state=42, tol=1e-3, **params)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    top_3_models.append(model)\n",
    "    top_3_params.append(params)\n",
    "    \n",
    "    # Informaci√≥n adicional sobre el modelo\n",
    "    print(f\"  Iteraciones: {model.n_iter_}\")\n",
    "    print(f\"  Coeficientes no-cero: {np.count_nonzero(model.coef_)}\")\n",
    "\n",
    "print(f\"\\n‚úì Top 3 modelos entrenados y listos para evaluaci√≥n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9cd69f",
   "metadata": {},
   "source": [
    "## 8. Evaluaci√≥n de M√©tricas de Regresi√≥n\n",
    "\n",
    "Calcular y comparar m√©tricas de regresi√≥n para los top 3 modelos en el conjunto de validaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6edb64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular m√©tricas para los top 3 modelos\n",
    "print(\"EVALUACI√ìN DE M√âTRICAS EN CONJUNTO DE VALIDACI√ìN\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "metrics_results = []\n",
    "\n",
    "for i, model in enumerate(top_3_models, 1):\n",
    "    # Predicciones en conjunto de validaci√≥n\n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    \n",
    "    # Calcular m√©tricas de regresi√≥n\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    explained_var = explained_variance_score(y_val, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # Para accuracy, convertir predicciones a clases binarias\n",
    "    # Asumiendo que la variable objetivo es binaria (0 o 1)\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "    y_val_binary = (y_val > 0.5).astype(int)\n",
    "    accuracy = accuracy_score(y_val_binary, y_pred_binary)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    metrics = {\n",
    "        'Modelo': f'Modelo #{i}',\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R¬≤': r2,\n",
    "        'Explained Variance': explained_var,\n",
    "        'Accuracy': accuracy,\n",
    "        'Par√°metros': str(top_3_params[i-1])\n",
    "    }\n",
    "    metrics_results.append(metrics)\n",
    "    \n",
    "    print(f\"\\nModelo #{i} - M√©tricas en Validaci√≥n:\")\n",
    "    print(f\"  ‚Ä¢ MSE: {mse:.6f}\")\n",
    "    print(f\"  ‚Ä¢ RMSE: {rmse:.6f}\")\n",
    "    print(f\"  ‚Ä¢ MAE: {mae:.6f}\")\n",
    "    print(f\"  ‚Ä¢ R¬≤: {r2:.6f}\")\n",
    "    print(f\"  ‚Ä¢ Explained Variance: {explained_var:.6f}\")\n",
    "    print(f\"  ‚Ä¢ Accuracy: {accuracy:.6f}\")\n",
    "    \n",
    "    # An√°lisis adicional de predicciones\n",
    "    print(f\"  ‚Ä¢ Rango de predicciones: [{y_pred.min():.3f}, {y_pred.max():.3f}]\")\n",
    "    print(f\"  ‚Ä¢ Media de predicciones: {y_pred.mean():.3f}\")\n",
    "\n",
    "# Crear DataFrame con todas las m√©tricas\n",
    "metrics_df = pd.DataFrame(metrics_results)\n",
    "print(f\"\\n‚úì M√©tricas calculadas para todos los modelos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b3301f",
   "metadata": {},
   "source": [
    "## 9. Visualizaci√≥n de M√©tricas de Regresi√≥n\n",
    "\n",
    "Crear gr√°ficos comparativos de las m√©tricas de regresi√≥n para los top 3 modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fc180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear visualizaciones de las m√©tricas\n",
    "print(\"CREANDO VISUALIZACIONES DE M√âTRICAS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Configurar el tama√±o de la figura\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Comparaci√≥n de M√©tricas de Regresi√≥n - Top 3 Modelos SGDRegressor', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "# Definir m√©tricas para visualizar\n",
    "metrics_to_plot = ['MSE', 'MAE', 'R¬≤', 'Explained Variance', 'Accuracy', 'RMSE']\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen']\n",
    "\n",
    "# Crear gr√°fico para cada m√©trica\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    # Extraer valores de la m√©trica\n",
    "    values = [metrics_results[i][metric] for i in range(3)]\n",
    "    models = [f'Modelo #{i+1}' for i in range(3)]\n",
    "    \n",
    "    # Crear gr√°fico de barras\n",
    "    bars = ax.bar(models, values, color=colors, alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    # Configurar el gr√°fico\n",
    "    ax.set_title(f'{metric}', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # A√±adir valores en las barras\n",
    "    for bar, value in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{value:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # Ajustar l√≠mites para mejor visualizaci√≥n\n",
    "    if metric in ['R¬≤', 'Explained Variance', 'Accuracy']:\n",
    "        ax.set_ylim(min(0, min(values) * 1.1), max(1, max(values) * 1.1))\n",
    "    else:\n",
    "        ax.set_ylim(0, max(values) * 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Visualizaciones creadas exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724f376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla comparativa de m√©tricas\n",
    "print(\"TABLA COMPARATIVA DE M√âTRICAS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Mostrar tabla con m√©tricas\n",
    "display_df = metrics_df[['Modelo', 'MSE', 'RMSE', 'MAE', 'R¬≤', 'Explained Variance', 'Accuracy']].copy()\n",
    "\n",
    "# Formatear n√∫meros para mejor lectura\n",
    "for col in ['MSE', 'RMSE', 'MAE', 'R¬≤', 'Explained Variance', 'Accuracy']:\n",
    "    display_df[col] = display_df[col].round(6)\n",
    "\n",
    "print(\"Resumen de m√©tricas para los top 3 modelos:\")\n",
    "display(display_df)\n",
    "\n",
    "# Identificar el mejor modelo para cada m√©trica\n",
    "print(\"\\nMejor modelo por m√©trica:\")\n",
    "print(\"-\" * 30)\n",
    "for metric in ['MSE', 'RMSE', 'MAE', 'R¬≤', 'Explained Variance', 'Accuracy']:\n",
    "    if metric in ['MSE', 'RMSE', 'MAE']:  # Menor es mejor\n",
    "        best_idx = display_df[metric].idxmin()\n",
    "    else:  # Mayor es mejor\n",
    "        best_idx = display_df[metric].idxmax()\n",
    "    \n",
    "    best_model = display_df.loc[best_idx, 'Modelo']\n",
    "    best_value = display_df.loc[best_idx, metric]\n",
    "    print(f\"‚Ä¢ {metric}: {best_model} ({best_value:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352069e8",
   "metadata": {},
   "source": [
    "## 10. An√°lisis de Validaci√≥n Cruzada\n",
    "\n",
    "Realizar validaci√≥n cruzada adicional en el mejor modelo para verificar su robustez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f3a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validaci√≥n cruzada del mejor modelo\n",
    "print(\"VALIDACI√ìN CRUZADA DEL MEJOR MODELO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "best_model = top_3_models[0]  # El primer modelo ya es el mejor\n",
    "\n",
    "# Definir m√©tricas para validaci√≥n cruzada\n",
    "cv_metrics = {\n",
    "    'neg_mean_squared_error': 'MSE',\n",
    "    'neg_mean_absolute_error': 'MAE',\n",
    "    'r2': 'R¬≤',\n",
    "    'explained_variance': 'Explained Variance'\n",
    "}\n",
    "\n",
    "cv_results = {}\n",
    "\n",
    "print(f\"Realizando validaci√≥n cruzada con {cv_folds} folds...\\n\")\n",
    "\n",
    "for scoring, metric_name in cv_metrics.items():\n",
    "    scores = cross_val_score(best_model, X_train_scaled, y_train, \n",
    "                           cv=cv_folds, scoring=scoring)\n",
    "    \n",
    "    # Para m√©tricas negativas, convertir a positivas\n",
    "    if 'neg_' in scoring:\n",
    "        scores = -scores\n",
    "    \n",
    "    cv_results[metric_name] = scores\n",
    "    \n",
    "    print(f\"{metric_name}:\")\n",
    "    print(f\"  ‚Ä¢ Media: {scores.mean():.6f}\")\n",
    "    print(f\"  ‚Ä¢ Desviaci√≥n est√°ndar: {scores.std():.6f}\")\n",
    "    print(f\"  ‚Ä¢ Rango: [{scores.min():.6f}, {scores.max():.6f}]\")\n",
    "    print(f\"  ‚Ä¢ Coeficiente de variaci√≥n: {(scores.std()/scores.mean())*100:.2f}%\")\n",
    "    print()\n",
    "\n",
    "# Evaluar estabilidad del modelo\n",
    "stability_score = np.mean([cv_results[m].std() for m in cv_results])\n",
    "print(f\"‚úì Validaci√≥n cruzada completada\")\n",
    "print(f\"Puntuaci√≥n de estabilidad promedio: {stability_score:.6f}\")\n",
    "print(f\"El modelo muestra {'alta' if stability_score < 0.05 else 'moderada' if stability_score < 0.1 else 'baja'} estabilidad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60ad17c",
   "metadata": {},
   "source": [
    "## 11. An√°lisis de Predicciones vs Valores Reales\n",
    "\n",
    "Crear visualizaciones para comparar predicciones vs valores reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45a53f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de predicciones vs valores reales\n",
    "print(\"AN√ÅLISIS DE PREDICCIONES VS VALORES REALES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Crear figura con subplots para los 3 modelos\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "fig.suptitle('Predicciones vs Valores Reales - Top 3 Modelos SGDRegressor', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, model in enumerate(top_3_models):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Hacer predicciones\n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    \n",
    "    # Crear scatter plot\n",
    "    ax.scatter(y_val, y_pred, alpha=0.6, color=colors[i])\n",
    "    \n",
    "    # L√≠nea perfecta (y = x)\n",
    "    min_val = min(y_val.min(), y_pred.min())\n",
    "    max_val = max(y_val.max(), y_pred.max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Predicci√≥n perfecta')\n",
    "    \n",
    "    # Configurar el gr√°fico\n",
    "    ax.set_xlabel('Valores Reales')\n",
    "    ax.set_ylabel('Predicciones')\n",
    "    ax.set_title(f'Modelo #{i+1}\\nR¬≤ = {r2_score(y_val, y_pred):.4f}')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    \n",
    "    # A√±adir l√≠nea de tendencia\n",
    "    z = np.polyfit(y_val, y_pred, 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax.plot(y_val, p(y_val), \"b--\", alpha=0.8, label=f'Tendencia (m={z[0]:.3f})')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Gr√°ficos de predicciones vs valores reales creados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a3a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de residuos para el mejor modelo\n",
    "print(\"AN√ÅLISIS DE RESIDUOS DEL MEJOR MODELO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "best_model = top_3_models[0]\n",
    "y_pred_best = best_model.predict(X_val_scaled)\n",
    "residuals = y_val - y_pred_best\n",
    "\n",
    "# Crear figura con an√°lisis de residuos\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('An√°lisis de Residuos - Mejor Modelo SGDRegressor', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Residuos vs Predicciones\n",
    "axes[0, 0].scatter(y_pred_best, residuals, alpha=0.6)\n",
    "axes[0, 0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0, 0].set_xlabel('Predicciones')\n",
    "axes[0, 0].set_ylabel('Residuos')\n",
    "axes[0, 0].set_title('Residuos vs Predicciones')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Histograma de residuos\n",
    "axes[0, 1].hist(residuals, bins=30, alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Residuos')\n",
    "axes[0, 1].set_ylabel('Frecuencia')\n",
    "axes[0, 1].set_title('Distribuci√≥n de Residuos')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Q-Q plot de residuos\n",
    "from scipy import stats\n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[1, 0])\n",
    "axes[1, 0].set_title('Q-Q Plot de Residuos')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Residuos vs Valores Reales\n",
    "axes[1, 1].scatter(y_val, residuals, alpha=0.6)\n",
    "axes[1, 1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1, 1].set_xlabel('Valores Reales')\n",
    "axes[1, 1].set_ylabel('Residuos')\n",
    "axes[1, 1].set_title('Residuos vs Valores Reales')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estad√≠sticas de residuos\n",
    "print(f\"Estad√≠sticas de residuos:\")\n",
    "print(f\"  ‚Ä¢ Media: {residuals.mean():.6f}\")\n",
    "print(f\"  ‚Ä¢ Desviaci√≥n est√°ndar: {residuals.std():.6f}\")\n",
    "print(f\"  ‚Ä¢ Sesgo: {stats.skew(residuals):.6f}\")\n",
    "print(f\"  ‚Ä¢ Curtosis: {stats.kurtosis(residuals):.6f}\")\n",
    "print(f\"  ‚Ä¢ Test de normalidad (Shapiro-Wilk): {stats.shapiro(residuals.sample(min(5000, len(residuals))))[1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4ed06d",
   "metadata": {},
   "source": [
    "## 12. Guardar Resultados y Modelos\n",
    "\n",
    "Guardar el mejor modelo y los resultados de la b√∫squeda de hiperpar√°metros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b10c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar resultados y modelos\n",
    "print(\"GUARDANDO RESULTADOS Y MODELOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Crear directorio para resultados\n",
    "results_dir = '../models/sgdregressor_results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Guardar el scaler (muy importante para SGDRegressor)\n",
    "scaler_path = os.path.join(results_dir, 'feature_scaler.joblib')\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"‚úì Scaler guardado: {scaler_path}\")\n",
    "\n",
    "# Guardar el mejor modelo\n",
    "best_model_path = os.path.join(results_dir, 'best_sgdregressor_model.joblib')\n",
    "joblib.dump(best_model, best_model_path)\n",
    "print(f\"‚úì Mejor modelo guardado: {best_model_path}\")\n",
    "\n",
    "# Guardar todos los top 3 modelos\n",
    "for i, model in enumerate(top_3_models, 1):\n",
    "    model_path = os.path.join(results_dir, f'top_{i}_model.joblib')\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"‚úì Modelo #{i} guardado: {model_path}\")\n",
    "\n",
    "# Guardar resultados de grid search\n",
    "grid_results_path = os.path.join(results_dir, 'grid_search_results.joblib')\n",
    "joblib.dump(grid_search, grid_results_path)\n",
    "print(f\"‚úì Resultados de Grid Search guardados: {grid_results_path}\")\n",
    "\n",
    "# Guardar m√©tricas en CSV\n",
    "metrics_path = os.path.join(results_dir, 'model_metrics.csv')\n",
    "metrics_df.to_csv(metrics_path, index=False)\n",
    "print(f\"‚úì M√©tricas guardadas: {metrics_path}\")\n",
    "\n",
    "# Crear resumen del experimento\n",
    "experiment_summary = {\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'algorithm': 'SGDRegressor',\n",
    "    'original_dataset_size': len(X_train_full),\n",
    "    'training_size': len(X_train),\n",
    "    'validation_size': len(X_val),\n",
    "    'features_count': X_train.shape[1],\n",
    "    'cv_folds': cv_folds,\n",
    "    'scaling_applied': 'StandardScaler',\n",
    "    'best_params': grid_search.best_params_,\n",
    "    'best_cv_score': float(grid_search.best_score_),\n",
    "    'best_model_iterations': int(best_model.n_iter_),\n",
    "    'search_duration': str(duration),\n",
    "    'validation_metrics': {\n",
    "        'mse': float(metrics_results[0]['MSE']),\n",
    "        'rmse': float(metrics_results[0]['RMSE']),\n",
    "        'mae': float(metrics_results[0]['MAE']),\n",
    "        'r2': float(metrics_results[0]['R¬≤']),\n",
    "        'explained_variance': float(metrics_results[0]['Explained Variance']),\n",
    "        'accuracy': float(metrics_results[0]['Accuracy'])\n",
    "    }\n",
    "}\n",
    "\n",
    "summary_path = os.path.join(results_dir, 'experiment_summary.json')\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(experiment_summary, f, indent=2)\n",
    "print(f\"‚úì Resumen del experimento guardado: {summary_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e805f48",
   "metadata": {},
   "source": [
    "## 13. Resumen Final\n",
    "\n",
    "Resumen completo del experimento de b√∫squeda de hiperpar√°metros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e49642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen final del experimento\n",
    "print(\"üéâ EXPERIMENTO DE B√öSQUEDA DE HIPERPAR√ÅMETROS COMPLETADO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"üìä ESTAD√çSTICAS DEL EXPERIMENTO:\")\n",
    "print(f\"  ‚Ä¢ Algoritmo utilizado: SGDRegressor\")\n",
    "print(f\"  ‚Ä¢ Dataset original: {len(X_train_full):,} registros\")\n",
    "print(f\"  ‚Ä¢ Conjunto de entrenamiento: {len(X_train):,} registros\")\n",
    "print(f\"  ‚Ä¢ Conjunto de validaci√≥n: {len(X_val):,} registros\")\n",
    "print(f\"  ‚Ä¢ N√∫mero de caracter√≠sticas: {X_train.shape[1]}\")\n",
    "print(f\"  ‚Ä¢ Escalado aplicado: StandardScaler\")\n",
    "\n",
    "print(f\"\\nüîç B√öSQUEDA DE HIPERPAR√ÅMETROS:\")\n",
    "print(f\"  ‚Ä¢ Folds de validaci√≥n cruzada: {cv_folds}\")\n",
    "print(f\"  ‚Ä¢ Tiempo total de b√∫squeda: {duration}\")\n",
    "print(f\"  ‚Ä¢ Mejor convergencia: {best_model.n_iter_} iteraciones\")\n",
    "\n",
    "print(f\"\\nüèÜ MEJORES RESULTADOS:\")\n",
    "print(f\"  ‚Ä¢ Mejores hiperpar√°metros: {grid_search.best_params_}\")\n",
    "print(f\"  ‚Ä¢ Mejor CV Score (MSE): {-grid_search.best_score_:.6f}\")\n",
    "print(f\"  ‚Ä¢ RMSE del mejor modelo: {np.sqrt(-grid_search.best_score_):.6f}\")\n",
    "\n",
    "# Mostrar las mejores m√©tricas en validaci√≥n\n",
    "best_metrics = metrics_results[0]\n",
    "print(f\"\\nüìà M√âTRICAS EN VALIDACI√ìN (MEJOR MODELO):\")\n",
    "print(f\"  ‚Ä¢ MSE: {best_metrics['MSE']:.6f}\")\n",
    "print(f\"  ‚Ä¢ RMSE: {best_metrics['RMSE']:.6f}\")\n",
    "print(f\"  ‚Ä¢ MAE: {best_metrics['MAE']:.6f}\")\n",
    "print(f\"  ‚Ä¢ R¬≤: {best_metrics['R¬≤']:.6f}\")\n",
    "print(f\"  ‚Ä¢ Explained Variance: {best_metrics['Explained Variance']:.6f}\")\n",
    "print(f\"  ‚Ä¢ Accuracy: {best_metrics['Accuracy']:.6f}\")\n",
    "\n",
    "print(f\"\\nüîß CARACTER√çSTICAS DEL MODELO:\")\n",
    "print(f\"  ‚Ä¢ Coeficientes activos: {np.count_nonzero(best_model.coef_)} de {len(best_model.coef_)}\")\n",
    "print(f\"  ‚Ä¢ Algoritmo de optimizaci√≥n: Stochastic Gradient Descent\")\n",
    "print(f\"  ‚Ä¢ Funci√≥n de p√©rdida: {best_model.loss}\")\n",
    "print(f\"  ‚Ä¢ Regularizaci√≥n: {best_model.penalty}\")\n",
    "\n",
    "print(f\"\\nüíæ ARCHIVOS GENERADOS:\")\n",
    "print(f\"  ‚Ä¢ Scaler: {scaler_path}\")\n",
    "print(f\"  ‚Ä¢ Mejor modelo: {best_model_path}\")\n",
    "print(f\"  ‚Ä¢ Top 3 modelos: {results_dir}/top_*_model.joblib\")\n",
    "print(f\"  ‚Ä¢ Resultados completos: {grid_results_path}\")\n",
    "print(f\"  ‚Ä¢ M√©tricas: {metrics_path}\")\n",
    "print(f\"  ‚Ä¢ Resumen: {summary_path}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Experimento completado exitosamente!\")\n",
    "print(f\"‚úÖ El modelo SGDRegressor est√° optimizado y listo para implementaci√≥n!\")\n",
    "print(f\"‚ö†Ô∏è Recordatorio: Usar el scaler guardado para preprocessar nuevos datos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
